{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.dirname(\"Image Collection.ipynb\")\n",
    "data_dir = os.path.join(script_dir, \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the list of gestures, a subfolder will be created for each one\n",
    "gestures = [\"1\", \"2\", \"3\", \"A\", \"B\"]\n",
    "\n",
    "# Specify the desired number of images for each gesture\n",
    "desired_amount = {\"1\": 200, \"2\": 200, \"3\": 200, \"A\": 100, \"B\": 100}\n",
    "\n",
    "# Initialize the dictionary of current number of occurrences per each gesture\n",
    "current_amount = {gesture: 0 for gesture in gestures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data folder if it does not exist yet\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "\n",
    "for gesture in gestures:\n",
    "    \n",
    "    # Create a subfolder per each gesture if it does not exist yet\n",
    "    new = os.path.join(data_dir, gesture)\n",
    "    if not os.path.exists(new):\n",
    "        os.makedirs(new)\n",
    "        \n",
    "    # If the subfolder exists, make sure that the ordering is correct and\n",
    "    # shift it if any skips are present\n",
    "    # (e.g. \"A_1.jpg\", \"A_2.jpg\", ... instead of \"A_1.jpg\", \"A_3.jpg\", ...)\n",
    "    else:\n",
    "        files = os.listdir(new)\n",
    "        files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "        l = len(files)\n",
    "        \n",
    "        # Go through each file and if the run order skips a count, shift the respective file's run order\n",
    "        for i in range(l - 1):\n",
    "            name_split = re.split(r\"[_|.]\", files[i])\n",
    "            name_split_next = re.split(r\"[_|.]\", files[i + 1])\n",
    "            if (int(name_split[1]) + 1) != int(name_split_next[1]):\n",
    "                new_name = name_split[0] + \"_\" + str(int(name_split[1]) + 1) + \".\" + name_split[2]\n",
    "                os.rename(os.path.join(new, files[i + 1]), os.path.join(new, new_name))\n",
    "                files = os.listdir(new)\n",
    "                files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "            \n",
    "        # Since the gesture subfolder is sorted by padding, we can use the last element as the current run\n",
    "        current_amount[gesture] = 0 if not files else int(re.split(r\"[_|.]\", files[-1])[1])\n",
    "\n",
    "paths = {gesture: os.path.join(data_dir, gesture) for gesture in gestures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rectangle in the frame that is cropped from the web camera image\n",
    "rect = [(225, 275), (425, 275), \n",
    "       (225, 475), (425, 475)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# Encapsulate the whole process to be able to close cameras in case of error\n",
    "try:\n",
    "    \n",
    "    # Establish the windows and place them accordingly\n",
    "    cv2.namedWindow(\"Camera view\")\n",
    "    cv2.resizeWindow(\"Camera view\", 640, 480)\n",
    "    cv2.moveWindow(\"Camera view\", 15, 200)\n",
    "\n",
    "    cv2.namedWindow(\"Grayscale view\")\n",
    "    cv2.resizeWindow(\"Grayscale view\", 480, 360)\n",
    "    cv2.moveWindow(\"Grayscale view\", 655, 30)\n",
    "\n",
    "    cv2.namedWindow(\"Binary view\")\n",
    "    cv2.resizeWindow(\"Binary view\", 480, 360)\n",
    "    cv2.moveWindow(\"Binary view\", 655, 430)\n",
    "\n",
    "    cv2.namedWindow(\"Example\")\n",
    "    cv2.resizeWindow(\"Example\", 380, 270)\n",
    "    cv2.moveWindow(\"Example\", 1125, 280)\n",
    "    \n",
    "    # Initialize variables for background substraction\n",
    "    frame_count = 0\n",
    "    background = None\n",
    "\n",
    "    # Perform the data collecting process for each gesture in the given gesture list\n",
    "    for gesture in gestures:\n",
    "\n",
    "        current = current_amount[gesture] + 1\n",
    "        counter = current\n",
    "        end = desired_amount[gesture]\n",
    "        flag = 0\n",
    "        exit = 0\n",
    "\n",
    "        # Continue until the respective subfolder has the designated number of samples\n",
    "        while counter <= end:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Check validity and avoid mirroring if frame is present\n",
    "            if not ret:\n",
    "                print(\"There has been a problem retrieving your frame\")\n",
    "                break\n",
    "            else:\n",
    "                frame_count += 1\n",
    "                frame = cv2.flip(frame, 1)\n",
    "\n",
    "            # End the process for the current gesture in case the \"q\" key is hit\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "            # End the whole process in case the \"Esc\" key is hit\n",
    "            if key == ord(\"\\x1b\"):\n",
    "                exit = 1\n",
    "                break\n",
    "\n",
    "            # Create grayscale version(s)\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Binarize these version(s) using thresholding\n",
    "                # Version using contouring and background mask\n",
    "            c=\"\"\"\n",
    "                # Version incorporating Nesrine's pieces of advice\n",
    "            frame_binary = cv2.GaussianBlur(frame_gray, (7, 7), 0)\n",
    "            # Create mask for the background\n",
    "            if background is None:\n",
    "                background = frame_binary.copy().astype(\"float\")\n",
    "            else:\n",
    "                if frame_count <= 30:\n",
    "                    background = cv2.accumulateWeighted(frame_binary, background, 0.5)\n",
    "                else:\n",
    "                    frame_binary = cv2.absdiff(background.astype(\"uint8\"), frame_gray)\n",
    "                    frame_binary = cv2.threshold(frame_binary, 70, 255, cv2.THRESH_BINARY)[1]\n",
    "                    #contours = cv2.findContours(frame_binary.copy(), \n",
    "                    #                            cv2.RETR_EXTERNAL, \n",
    "                    #                            cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "                    #segmentation = max(contours, key=cv2.countourArea) if contours else None\"\"\"\n",
    "\n",
    "            \n",
    "            #kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "            #frame_binary = cv2.morphologyEx(frame_binary, cv2.MORPH_GRADIENT, kernel)\n",
    "            #frame_binary = cv2.erode(frame_binary, kernel, iterations=1)\n",
    "            #frame_binary = cv2.dilate(frame_binary, kernel, iterations=1)\n",
    "            #frame_binary = cv2.medianBlur(frame_binary, 3)\n",
    "            #frame_binary = cv2.threshold(frame_gray, 150, 255, cv2.THRESH_BINARY)[1]\n",
    "            #frame_binary = cv2.erode(frame_binary, kernel, iterations=3)\n",
    "            #frame_binary = cv2.dilate(frame_binary, kernel, iterations=2)\n",
    "            #frame_binary = cv2.morphologyEx(frame_binary, cv2.MORPH_GRADIENT, kernel)\n",
    "            \n",
    "                # Good adaptive version (fastNlMeansDenoising (5, 15, 7) + 2 median blurs (5) + adaptive thresholding (3, 1))\n",
    "            #frame_gray = cv2.fastNlMeansDenoising(frame_gray, None, 5, 15, 7)\n",
    "            #frame_gray = cv2.medianBlur(frame_gray, 5)\n",
    "            #frame_gray = cv2.medianBlur(frame_gray, 5)\n",
    "            #frame_binary = cv2.adaptiveThreshold(frame_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 3, 2)\n",
    "            \n",
    "            \n",
    "                # Good binary version (fastNlMeansDenoising (5, 15, 7) + 1 gaussian blur((7, 7), 0) + binary thresholding (150))\n",
    "            #frame_gray = cv2.fastNlMeansDenoising(frame_gray, None, 5, 15, 7)\n",
    "            frame_gray = cv2.GaussianBlur(frame_gray, (7, 7), 0)\n",
    "            frame_binary = cv2.threshold(frame_gray, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Show all images\n",
    "            # Live view with frame and text\n",
    "            cv2.rectangle(frame, rect[0], rect[3], (0, 255, 0), 2)\n",
    "            #acc = 0.0\n",
    "            #txt = gesture.capitalize() + f\" ({str(round(acc, 2))} %)\"      # in preparation for model version\n",
    "            txt = gesture.capitalize()\n",
    "            cv2.putText(frame, txt, (rect[0][0], rect[0][1] - 15), \n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Camera view\", frame)\n",
    "\n",
    "            # Grayscale version(s)\n",
    "            cv2.imshow(\"Grayscale view\", cv2.resize(frame_gray, (480, 360)))\n",
    "\n",
    "            # Binary version(s)\n",
    "            if frame_count > 0:\n",
    "                cv2.imshow(\"Binary view\", cv2.resize(frame_binary, (480, 360)))\n",
    "\n",
    "            if not flag:\n",
    "                time.sleep(1)\n",
    "            flag = 1\n",
    "\n",
    "            # To reduce the number of almost identical frames, only save every n frames\n",
    "            if not current % 4:\n",
    "\n",
    "                # Create the naming for the file with the desired padding, i.e. (\"gesture_run-number.jpg\")\n",
    "                img_name = gesture + \"_\" + str(counter) + \".jpg\"\n",
    "                img_path = r\"%s\" %os.path.join(paths[gesture], img_name)\n",
    "\n",
    "                # Save the cropped rectangle from the frame\n",
    "                if not cv2.imwrite(img_path, \n",
    "                                   frame_binary[(rect[0][1] + 2):(rect[2][1] - 2), \n",
    "                                                (rect[0][0] + 2):(rect[1][0] - 2)]):\n",
    "                    print(\"Something went wrong during this attempt:\",\n",
    "                          f\"gesture - {gesture}, run - {counter}\")\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "            current += 1\n",
    "\n",
    "        if exit:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Close the camera and all windows in case of unexpected fatality\n",
    "except:\n",
    "    print(\"A fatality has occured, the program will now terminate\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
