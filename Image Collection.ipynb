{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.dirname(\"Image Collection.ipynb\")\n",
    "data_dir = os.path.join(script_dir, \"Data\")\n",
    "example_dir = os.path.join(script_dir, \"Examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the list of gestures, a subfolder will be created for each one\n",
    "gestures = [\"1\", \"2\", \"3\", \"A\", \"B\"]\n",
    "\n",
    "# Specify the desired number of images for each gesture\n",
    "desired_amount = {\"1\": 200, \"2\": 200, \"3\": 200, \"A\": 500, \"B\": 1000}\n",
    "\n",
    "# Initialize the dictionary of current number of occurrences per each gesture\n",
    "current_amount = {gesture: 0 for gesture in gestures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data folder if it does not exist yet\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Create Examples folder if it does not exist yet\n",
    "if not os.path.exists(example_dir):\n",
    "    os.makedirs(example_dir)\n",
    "\n",
    "for gesture in gestures:\n",
    "    \n",
    "    # Create a subfolder per each gesture if it does not exist yet\n",
    "    new = os.path.join(data_dir, gesture)\n",
    "    if not os.path.exists(new):\n",
    "        os.makedirs(new)\n",
    "        \n",
    "    # If the subfolder exists, make sure that the ordering is correct and\n",
    "    # shift it if any skips are present\n",
    "    # (e.g. \"A_1.jpg\", \"A_2.jpg\", ... instead of \"A_1.jpg\", \"A_3.jpg\", ...)\n",
    "    else:\n",
    "        files = os.listdir(new)\n",
    "        files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "        l = len(files)\n",
    "        \n",
    "        # Go through each file and if the run order skips a count, shift the respective file's run order\n",
    "        for i in range(l - 1):\n",
    "            name_split = re.split(r\"[_|.]\", files[i])\n",
    "            name_split_next = re.split(r\"[_|.]\", files[i + 1])\n",
    "            if (int(name_split[1]) + 1) != int(name_split_next[1]):\n",
    "                new_name = name_split[0] + \"_\" + str(int(name_split[1]) + 1) + \".\" + name_split[2]\n",
    "                os.rename(os.path.join(new, files[i + 1]), os.path.join(new, new_name))\n",
    "                files = os.listdir(new)\n",
    "                files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "            \n",
    "        # Since the gesture subfolder is sorted by padding, we can use the last element as the current run\n",
    "        current_amount[gesture] = 0 if not files else int(re.split(r\"[_|.]\", files[-1])[1])\n",
    "\n",
    "    # Create blank example for each gesture if the example has not been added yet\n",
    "    new = os.path.join(example_dir, gesture + \".jpg\")\n",
    "    if not os.path.exists(new):\n",
    "        cv2.imwrite(f\"{new}\", np.ones((540, 960)) * 255)\n",
    "\n",
    "paths = {gesture: os.path.join(data_dir, gesture) for gesture in gestures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rectangle in the frame that is cropped from the web camera image\n",
    "rect = [(10, 10), (210, 10), \n",
    "       (10, 210), (210, 210)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rectangle in the frame that is cropped from the web camera image\n",
    "rect = [(225, 275), (425, 275), \n",
    "       (225, 475), (425, 475)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_capturing(method=\"adaptive\", binary_threshold=0, last_mask=-1):\n",
    "    \"\"\"Capture image from the camera, convert it to grayscale \n",
    "    and then perform preprocessing and thresholding.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    method (string) -- hand segmentation method selection from (default adaptive)\n",
    "        mask = use background substraction based on mask taken at the beginning\n",
    "        adaptive = use adaptive thresholding methods\n",
    "    binary_thresh (integer) -- the thresholding parameter for binary thresholding in mask method (default 150)\n",
    "    last_mask (integer) -- the last frame to consider for the creation of background mask in mask method\n",
    "    \"\"\"\n",
    "    # Input management\n",
    "    if method not in [\"adaptive\", \"mask\"]:\n",
    "        raise ValueError(\"Method other than adaptive or mask has been given as input\")\n",
    "    \n",
    "    if not isinstance(binary_threshold, int):\n",
    "        raise ValueError(\"Different datatype than integer has been given as input for binary threshold\")\n",
    "    \n",
    "    if not isinstance(last_mask, int):\n",
    "        raise ValueError(\"Different datatype than integer has been given as input for last frame of background mask\")\n",
    "    \n",
    "    if method == \"mask\" and binary_threshold == 0:\n",
    "        wrn = \"\\nMask thresholding method has been chosen but binary threshold has not been specified.\"\n",
    "        wrn += \"\\nThis will result in a fully one-colored image, please specify the threshold\"\n",
    "        warnings.warn(wrn)\n",
    "\n",
    "    if method == \"mask\" and (binary_threshold < 0 or binary_threshold >= 255):\n",
    "        wrn = \"\\nMask thresholding method has been chosen but binary threshold is under 0 or over 255.\"\n",
    "        wrn += \"\\nThis will result in a fully one-colored image, please specify different threshold (between 1 and 254)\"\n",
    "        warnings.warn(wrn)\n",
    "\n",
    "    if method == \"mask\" and last_mask <= 10:\n",
    "        if last_mask == -1:\n",
    "            wrn = \"\\nBackground substraction thresholding method has been chosen but last mask frame has not been specified.\"\n",
    "        else:\n",
    "            wrn = \"\\nBackground substraction thresholding method has been chosen but last mask frame is very low (<= 10).\"\n",
    "        wrn += \"\\nThis may result in unpredictable behaviour and possibly crash of the whole script, please correct the parameter\"\n",
    "        warnings.warn(wrn)\n",
    "\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "    # Encapsulate the whole process to be able to close cameras in case of error\n",
    "    try:\n",
    "\n",
    "        # Establish the windows and place them accordingly\n",
    "        cv2.namedWindow(\"Camera view\")\n",
    "        cv2.resizeWindow(\"Camera view\", 640, 480)\n",
    "        cv2.moveWindow(\"Camera view\", 15, 200)\n",
    "\n",
    "        cv2.namedWindow(\"Grayscale view\")\n",
    "        cv2.resizeWindow(\"Grayscale view\", 480, 360)\n",
    "        cv2.moveWindow(\"Grayscale view\", 655, 30)\n",
    "\n",
    "        cv2.namedWindow(\"Binary view\")\n",
    "        cv2.resizeWindow(\"Binary view\", 480, 360)\n",
    "        cv2.moveWindow(\"Binary view\", 655, 430)\n",
    "\n",
    "        cv2.namedWindow(\"Example\")\n",
    "        cv2.resizeWindow(\"Example\", 380, 270)\n",
    "        cv2.moveWindow(\"Example\", 1125, 280)\n",
    "\n",
    "        # Initialize variables for background substraction\n",
    "        frame_count = 0\n",
    "        background = None\n",
    "\n",
    "        # Perform the data collecting process for each gesture in the given gesture list\n",
    "        for gesture in gestures:\n",
    "\n",
    "            # Initialize necessary variables (different per gesture)\n",
    "            current = current_amount[gesture] + 1\n",
    "            counter = current\n",
    "            end = desired_amount[gesture]\n",
    "            flag = 0 # To know when a new gesture is being taken for the first time\n",
    "            exit = 0 # To let the user end the process early by clicking the \"Esc\" key\n",
    "\n",
    "            # Continue until the respective subfolder has the designated number of samples\n",
    "            while counter <= end:\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Check validity and avoid mirroring if frame is present\n",
    "                if not ret:\n",
    "                    print(\"There has been a problem retrieving your frame\")\n",
    "                    break\n",
    "                else:\n",
    "                    frame_count += 1\n",
    "                    frame = cv2.flip(frame, 1)\n",
    "\n",
    "                # End the process for the current gesture in case the \"q\" key is hit\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == ord(\"q\"):\n",
    "                    break\n",
    "\n",
    "                # End the whole process in case the \"Esc\" key is hit\n",
    "                if key == ord(\"\\x1b\"):\n",
    "                    exit = 1\n",
    "                    break\n",
    "\n",
    "                # Create grayscale version\n",
    "                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Binarize the grayscale image using thresholding (with various methods)\n",
    "                frame_binary = frame_gray[(rect[0][1] + 2):(rect[2][1] - 2), \n",
    "                                          (rect[0][0] + 2):(rect[1][0] - 2)]\n",
    "                \n",
    "                # Version using background mask\n",
    "                if method == \"mask\":\n",
    "                    # Create mask for the background\n",
    "                    if background is None:\n",
    "                        background = frame_binary.copy().astype(\"float\")\n",
    "                    else:\n",
    "                        if frame_count <= last_mask:\n",
    "                            background = cv2.accumulateWeighted(frame_binary, background, 0.5)\n",
    "                        # Use the mask for background substraction\n",
    "                        else:\n",
    "                            frame_binary = cv2.absdiff(background.astype(\"uint8\"), frame_binary)\n",
    "                            frame_binary = cv2.GaussianBlur(frame_binary, (3, 3), 0)\n",
    "                            frame_binary = cv2.threshold(frame_binary, binary_threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "                # Version using adaptive thresholding\n",
    "                elif method == \"adaptive\":\n",
    "                    # For now (fastNlMeansDenoising (5, 15, 7) + 2 median blurs (5) + adaptive thresholding (3, 1))\n",
    "                    frame_binary = cv2.fastNlMeansDenoising(frame_binary, None, 5, 15, 7)\n",
    "                    frame_binary = cv2.medianBlur(frame_binary, 3)\n",
    "                    frame_binary = cv2.GaussianBlur(frame_binary, (3, 3), 0)\n",
    "                    frame_binary = cv2.adaptiveThreshold(frame_binary, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                                         cv2.THRESH_BINARY_INV, 3, 2)\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "                    frame_binary = cv2.morphologyEx(frame_binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "                # Show all images\n",
    "                \n",
    "                # Live view with frame and text\n",
    "                cv2.rectangle(frame, rect[0], rect[3], (0, 255, 0), 2)\n",
    "                #acc = 0.0\n",
    "                #txt = gesture.capitalize() + f\" ({str(round(acc, 2))} %)\"      # in preparation for model version\n",
    "                txt = gesture.capitalize()\n",
    "                cv2.putText(frame, txt, (rect[0][0], rect[0][1] - 15), \n",
    "                            cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.imshow(\"Camera view\", frame)\n",
    "\n",
    "                # Grayscale version\n",
    "                cv2.imshow(\"Grayscale view\", cv2.resize(frame_gray, (480, 360)))\n",
    "\n",
    "                # Binary version\n",
    "                if frame_count > last_mask:\n",
    "                    cv2.imshow(\"Binary view\", cv2.resize(frame_binary, (480, 360)))\n",
    "\n",
    "                # Show example on new gesture\n",
    "                if not flag:\n",
    "                    example = cv2.imread(f\"{os.path.join(example_dir, gesture)}\" + \".jpg\")\n",
    "                    cv2.imshow(\"Example\", cv2.resize(example, (380, 270)))\n",
    "                    time.sleep(1)\n",
    "                    flag = 1\n",
    "\n",
    "                # To reduce the number of almost identical frames, only save every n frames\n",
    "                if not current % 4:\n",
    "\n",
    "                    # Create the naming for the file with the desired padding, i.e. (\"gesture_run-number.jpg\")\n",
    "                    img_name = gesture + \"_\" + str(counter) + \".jpg\"\n",
    "                    img_path = r\"%s\" %os.path.join(paths[gesture], img_name)\n",
    "\n",
    "                    # Save the cropped rectangle from the frame\n",
    "                    if not cv2.imwrite(img_path, \n",
    "                                       frame_binary):\n",
    "                        print(\"Something went wrong during this attempt:\",\n",
    "                              f\"gesture - {gesture}, run - {counter}\")\n",
    "\n",
    "                    counter += 1\n",
    "\n",
    "                current += 1\n",
    "\n",
    "            if exit:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "\n",
    "    # Close the camera and all windows in case of unexpected fatality\n",
    "    except:\n",
    "        print(\"A fatality has occured, the program will now terminate\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_capturing(method=\"adaptive\")\n",
    "image_capturing(method=\"mask\", binary_threshold=50, last_mask=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of some morphological operations I have experimented with (with no real success)\n",
    "\n",
    "#kernel = np.ones((5, 5), np.uint8)\n",
    "#kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "#frame_binary = cv2.morphologyEx(frame_binary, cv2.MORPH_GRADIENT, kernel)\n",
    "#frame_binary = cv2.erode(frame_binary, kernel, iterations=1)\n",
    "#frame_binary = cv2.dilate(frame_binary, kernel, iterations=1)\n",
    "#frame_binary = cv2.medianBlur(frame_binary, 3)\n",
    "#frame_binary = cv2.threshold(frame_gray, 150, 255, cv2.THRESH_BINARY)[1]\n",
    "#frame_binary = cv2.erode(frame_binary, kernel, iterations=3)\n",
    "#frame_binary = cv2.dilate(frame_binary, kernel, iterations=2)\n",
    "#frame_binary = cv2.morphologyEx(frame_binary, cv2.MORPH_GRADIENT, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to find contours in the binarized frame and add them to the original frame\n",
    "\n",
    "# Find contours and draw them into the original image\n",
    "#contours = cv2.findContours(frame_binary.copy(), \n",
    "#                            cv2.RETR_EXTERNAL, \n",
    "#                            cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "#if contours:\n",
    "#    cv2.drawContours(frame, \n",
    "#                     max(contours, key=cv2.contourArea) + rect[0], \n",
    "#                     -1, \n",
    "#                     (0, 0, 255), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
