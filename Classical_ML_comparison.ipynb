{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a71ac7b",
   "metadata": {},
   "source": [
    "<h1>Dataset Preprocessing to Enable Application of Classical ML Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "250cc579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e8a40f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1d153247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import build_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "368d83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file from json in the given folder\n",
    "with open(\"config.json\", \"r\") as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e649e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the list of gestures\n",
    "with open(config[\"Paths\"][\"Gesture list\"], \"r\") as gesture_list:\n",
    "    gestures = gesture_list.readlines()[0].split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "49cc51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = config[\"General parameters\"][\"Image size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "49925073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26351 files belonging to 49 classes.\n",
      "Using 21081 files for training.\n",
      "Using 5270 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_images, test_images = tf.keras.preprocessing.image_dataset_from_directory(\"Data\",\n",
    "                                                                                labels=\"inferred\",\n",
    "                                                                                label_mode=\"int\",\n",
    "                                                                                class_names=gestures,\n",
    "                                                                                color_mode=\"rgb\",\n",
    "                                                                                batch_size=256,\n",
    "                                                                                image_size=(img_size,\n",
    "                                                                                            img_size),\n",
    "                                                                                shuffle=True,\n",
    "                                                                                seed=42,\n",
    "                                                                                validation_split=0.2,\n",
    "                                                                                subset=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bf1a7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default preprocessing pipeline if not specified\n",
    "preprocessing_layers = config[\"Model\"][\"Default preprocessing\"]\n",
    "\n",
    "# Build the preprocessing pipeline according to given instructions\n",
    "preprocessing = build_preprocessing(inp_shape=[img_size,\n",
    "                                               img_size,\n",
    "                                               3],\n",
    "                                    instructions=preprocessing_layers,\n",
    "                                    name=\"preprocessing_pipeline\")\n",
    "img_size = 128\n",
    "resize = tf.keras.layers.Resizing(img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "992fd40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same preprocessing steps as for the CNN but flatten the images\n",
    "train_images = train_images.map(lambda x, y: (tf.reshape(resize(preprocessing(x)), [-1, img_size ** 2]), y)).unbatch()\n",
    "test_images = test_images.map(lambda x, y: (tf.reshape(resize(preprocessing(x)), [-1, img_size ** 2]), y)).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c7f605f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15684\\669120183.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert the tf.data.Datasets to numpy arrays containing image & label per sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\asl\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_utils.py\u001b[0m in \u001b[0;36m_eager_dataset_iterator\u001b[1;34m(ds)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_eager_dataset_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNumpyElem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32myield\u001b[0m \u001b[0mtree_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_elem_to_numpy_eager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\asl\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    785\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\asl\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[1;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 770\u001b[1;33m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[0;32m    771\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\asl\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3036\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3038\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3039\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IteratorGetNext\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3040\u001b[0m         \"output_shapes\", output_shapes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convert the tf.data.Datasets to numpy arrays containing image & label per sample\n",
    "train_images = np.fromiter(tfds.as_numpy(train_images), dtype=tuple, count=-1)\n",
    "test_images = np.fromiter(tfds.as_numpy(test_images), dtype=tuple, count=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daeada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the images and the labels separately\n",
    "train_X, train_y = np.vstack([element[0] for element in train_images]), np.ravel(np.vstack([element[1] for element in train_images]))\n",
    "test_X, test_y = np.vstack([element[0] for element in test_images]), np.ravel(np.vstack([element[1] for element in test_images]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check memory consumption for the training dataset\n",
    "print(\"Training dataset memory consumption: {:.1f}MB\".format(train_X.nbytes / (1024 * 1024.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b437dcf4",
   "metadata": {},
   "source": [
    "<h1>k-NN Gesture Classification</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195314ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05968405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the k-NN classifier\n",
    "k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=k,\n",
    "                           n_jobs=-1)\n",
    "knn.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87200211",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d85234",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c91fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier on the test dataset\n",
    "knn_predictions = knn.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y,\n",
    "                            knn_predictions,\n",
    "                            labels=gestures,\n",
    "                            target_names=gestures))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
