{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_folder(dir_name, verbose=False):\n",
    "    \"\"\"\n",
    "    Check whether given directory exists and create new one if not.\n",
    "    \n",
    "    Parameters:\n",
    "        dir_name: string\n",
    "            Name of the directory to be checked and to be created.\n",
    "        verbose: bool (default False)\n",
    "            Whether or not to inform the user about the creation of the folder.\n",
    "    \"\"\"\n",
    "    # Input management\n",
    "    if not isinstance(dir_name, str):\n",
    "        raise ValueError(\"Different datatype than string has been given as input for name of the directory.\")\n",
    "\n",
    "    if not isinstance(verbose, bool):\n",
    "        raise ValueError(\"Different datatype than boolean has been given as input for the verbose parameter\")\n",
    "\n",
    "    # Check directory's existence and try to create it if not existing and if possible\n",
    "    if not os.path.exists(dir_name):\n",
    "        try:\n",
    "            os.makedirs(dir_name)\n",
    "            if verbose:\n",
    "                print(f\"A folder has been successfully created with this path: {dir_name}\")\n",
    "        except OSError:\n",
    "            wrn = \"\\nThe path you have specified for the new folder to-be created is invalid.\"\n",
    "            wrn += \"\\nThe folder does not exist and was not created. Please specify a correct path.\"\n",
    "            warnings.warn(wrn)\n",
    "\n",
    "    elif verbose:\n",
    "        print(f\"A folder with this name already exists: {dir_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_padding(dir_name):\n",
    "    \"\"\"\n",
    "    Images padded as A_1.jpg, A_2.jpg, ... are expected for the project.\n",
    "    This function detects skips in padding (e.g. A_1.jpg, A_3.jpg) and repairs these.\n",
    "\n",
    "    Parameters:\n",
    "        dir_name: str\n",
    "            Path to the directory that needs repair.\n",
    "    \"\"\"\n",
    "    # Input management\n",
    "    if not isinstance(dir_name, str):\n",
    "        raise ValueError(\"Different datatype than string has been given as input for name of the directory.\")\n",
    "\n",
    "    if not os.path.exists(dir_name):\n",
    "        warnings.warn(\"\\nDirectory with given path does not exist. No padding adjustments have been made, returning.\")\n",
    "        return\n",
    "\n",
    "    # Obtain the list of files in the folder\n",
    "    files = os.listdir(dir_name)\n",
    "    files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "    filecount = len(files)\n",
    "\n",
    "    # The first image should have 1 in it's padding, rename it if necessary\n",
    "    if filecount:\n",
    "        first_split = re.split(r\"[_|.]\", files[0])\n",
    "        if int(first_split[1]) != 1:\n",
    "            new_name = first_split[0] + \"_\" + str(1) + \".\" + first_split[2]\n",
    "            os.rename(os.path.join(dir_name, files[0]), os.path.join(dir_name, new_name))\n",
    "            files = os.listdir(dir_name)\n",
    "            files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "        \n",
    "    # Go through each file and if the run order skips a count, shift all the following files' padding\n",
    "    for i in range(filecount - 1):\n",
    "        name_split = re.split(r\"[_|.]\", files[i])\n",
    "        name_split_next = re.split(r\"[_|.]\", files[i + 1])\n",
    "\n",
    "        # Stop the process if there is some unexpected (i.e. < 1) number in padding\n",
    "        if int(name_split_next[1]) < 1:\n",
    "            wrn = f\"\\nIn the folder {dir_name} there is a file {files[i + 1]} with non-positive numbering!\\n\"\n",
    "            wrn += \"This might result in unexpected behaviour. The repair process will now terminate, please correct the number.\"\n",
    "            warnings.warn(wrn)\n",
    "            return\n",
    "\n",
    "        # Warn the user if there is some mix of gestures\n",
    "        if name_split[0] != name_split_next[0]:\n",
    "            warnings.warn(f\"There are files with different naming in the current directory ({dir_name}): {files[i]}, {files[i + 1]}!\")\n",
    "\n",
    "        # Find the padding jump\n",
    "        diff = int(name_split_next[1]) - int(name_split[1])\n",
    "\n",
    "        # The expected padding difference is one, \n",
    "        # otherwise something is missing and all following files need to be shifted\n",
    "        if diff != 1:\n",
    "            for j in range(i + 1, filecount):\n",
    "                name_current = re.split(r\"[_|.]\", files[j])\n",
    "                new_name = name_current[0] + \"_\" + str(int(name_current[1]) - diff + 1) + \".\" + name_current[2]\n",
    "                os.rename(os.path.join(dir_name, files[j]), os.path.join(dir_name, new_name))\n",
    "\n",
    "            # Get the new list of files with adjusted padding\n",
    "            files = os.listdir(dir_name)\n",
    "            files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_folders(script_directory, gestures_list, amount_per_gesture):\n",
    "    \"\"\"\n",
    "    Setup folders for the project. Add directories for data and examples\n",
    "    and subfolders for each gesture in the list of gestures. Also setup\n",
    "    the current and desired amounts for each gesture.\n",
    "    \n",
    "    Parameters:\n",
    "        script_directory: str\n",
    "            Name of the directory where the script is located. All folders\n",
    "            will be created in this directory.\n",
    "        gestures_list: list of strings\n",
    "            List of all gestures to be included in the project. \n",
    "            Subfolder will be created for each one in the Data folder.\n",
    "            Example should be present for each one in Examples folder.\n",
    "        amount_per_gesture: int\n",
    "            Positive integer that specifies the desired number of datapoints per gesture.\n",
    "\n",
    "    Returns:\n",
    "        data_directory: str\n",
    "            Directory name for the Data folder. Subfolders for each gesture are located in this folder.\n",
    "        example_directory: str\n",
    "            Directory name of the Examples folder.\n",
    "            If not present beforehand, it is created and filled with dummy images per gesture.\n",
    "        desired_amount: dict of str: int pairs\n",
    "            Dictionary of desired amounts of samples per each gesture.\n",
    "        current_amount: dict of str: int pairs\n",
    "            Dictionary of current amounts of samples per each gesture.\n",
    "        paths: dict of str: str\n",
    "            Dictionary of paths to all the gestures.\n",
    "    \"\"\"\n",
    "    # Input management\n",
    "    if not isinstance(script_directory, str):\n",
    "        raise ValueError(\"Different datatype than string has been given as input for name of the script directory.\")\n",
    "    else:\n",
    "        if not script_directory:\n",
    "            warnings.warn(\"Given script directory is empty, thus all the processes will run in the location of this script.\")\n",
    "        else:\n",
    "            if not os.path.exists(script_directory):\n",
    "                raise ValueError(\"The given directory for the script does not exist, please specify a correct directory path.\")\n",
    "\n",
    "    if not isinstance(gestures_list, list):\n",
    "        raise ValueError(\"Different datatype than list has been given as input for the list of gestures.\")\n",
    "    else:\n",
    "        for val in gestures_list:\n",
    "            if not isinstance(val, str):\n",
    "                raise ValueError(\"There is a value with different datatype than string in the list of gestures.\")\n",
    "        if len(gestures_list) != len(set(gestures_list)):\n",
    "            raise ValueError(\"There are some gesture duplicates in the list of gestures, please check.\")\n",
    "\n",
    "    if not isinstance(amount_per_gesture, int):\n",
    "        raise ValueError(\"Different datatype than integer has been given as input for the desired amount per gesture.\")\n",
    "\n",
    "    if amount_per_gesture < 0:\n",
    "        raise ValueError(\"Negative number has been given as input for the desired amount per gesture.\")\n",
    "\n",
    "    # Specify the desired number of images for each gesture\n",
    "    desired_amount = {gesture: amount_per_gesture for gesture in gestures_list}\n",
    "\n",
    "    # Initialize the dictionary of current number of occurrences per each gesture\n",
    "    current_amount = {gesture: 0 for gesture in gestures_list}\n",
    "\n",
    "    # Initialize folder names, initialize paths dictionary\n",
    "    data_dir = os.path.join(script_directory, \"Data\")\n",
    "    example_dir = os.path.join(script_directory, \"Examples\")\n",
    "    paths = {}\n",
    "\n",
    "    # Create Data and Example folders if they do not not exist yet\n",
    "    new_folder(data_dir, verbose=True)\n",
    "    new_folder(example_dir, verbose=True)\n",
    "\n",
    "    for gesture in gestures_list:\n",
    "\n",
    "        # Create a subfolder per each gesture if it does not exist yet and add it to paths\n",
    "        new = os.path.join(data_dir, gesture)\n",
    "        new_folder(new)\n",
    "        paths[gesture] = new\n",
    "\n",
    "        # If the subfolder exists, make sure that the ordering is correct and\n",
    "        # shift it if any skips are present\n",
    "        # (e.g. \"A_1.jpg\", \"A_2.jpg\", ... instead of \"A_1.jpg\", \"A_3.jpg\", ...)\n",
    "        repair_padding(new)\n",
    "\n",
    "        # Since the directory is now correctly sorted by padding, we can read the current amounts\n",
    "        files = os.listdir(new)\n",
    "        files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "        current_amount[gesture] = 0 if not files else int(re.split(r\"[_|.]\", files[-1])[1])\n",
    "\n",
    "        # Create a dummy example image for the current gesture if it does not have an example image yet\n",
    "        new = os.path.join(example_dir, gesture + \".jpg\")\n",
    "        if not os.path.exists(new):\n",
    "            cv2.imwrite(f\"{new}\", np.ones((540, 960)) * 255)\n",
    "            warnings.warn(f\"\\nThe current gesture ({gesture}) does not have an example image yet, a dummy image has been created instead.\")\n",
    "\n",
    "    return data_dir, example_dir, desired_amount, current_amount, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rectangle(origin, size_X, size_Y):\n",
    "    \"\"\"\n",
    "    Function to create the rectangle shape with given properties\n",
    "    \n",
    "    Parameters:\n",
    "        origin: tuple of int, int\n",
    "            Upper left corner of the rectangle.\n",
    "        size_X: int\n",
    "            Width of the rectangle\n",
    "        size_Y: int\n",
    "            Height of the rectangle\n",
    "\n",
    "    Returns:\n",
    "        rectangle: list of 4 tuples of (int, int)\n",
    "            The coordinates for the upper left, upper right, lower left and lower right corner\n",
    "    \"\"\"\n",
    "    if not isinstance(origin, tuple):\n",
    "        raise ValueError(\"Different datatype than tuple has been given as input for the origin.\")\n",
    "    elif len(origin) != 2:\n",
    "        raise ValueError(\"Different dimension than 2 given for the origin of the rectangle.\")\n",
    "    else:\n",
    "        for val in origin:\n",
    "            if not isinstance(val, int):\n",
    "                raise ValueError(\"Different datatype than integer has been given for the coordinates of the origin.\")\n",
    "            elif val < 0:\n",
    "                raise ValueError(\"The coordinates for the origin cannot be negative.\")\n",
    "\n",
    "    if not isinstance(size_X, int) or not isinstance(size_Y, int):\n",
    "        raise ValueError(\"The height and width of the rectangle must be integers.\")\n",
    "    elif size_X < 0 or size_Y < 0:\n",
    "        raise ValueError(\"The height and width of the rectangle must be positive integers.\")\n",
    "\n",
    "    X, Y = origin\n",
    "    upper_right, lower_left, lower_right = (X + size_X, Y), (X, Y + size_Y), (X + size_X, Y + size_Y)\n",
    "    return [origin, upper_right, lower_left, lower_right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_capturing(gesture_list, examples=\"Examples\", save=True, predict=False, \n",
    "                    data_directory=None, current_amounts=None, desired_amounts=None, \n",
    "                    gesture_paths=None, model=None):\n",
    "    \"\"\"\n",
    "    Function for image capturing. Enables usage as data collector or purely as image obtainer.\n",
    "    If the save parameter is True, thresholded binary images in the rectangle you see on the screen\n",
    "    will be saved in appropriate directory for each gesture.\n",
    "    \n",
    "    Throughout the run of the function, you can use the following commands by using keys on your keyboard:\n",
    "        Esc - terminate the whole process\n",
    "        q - skip the current gesture and move to the next one\n",
    "        l - switch language from English to Czech and vice versa\n",
    "        spacebar - move the rectangle into the other position (one should be more comfortable for fingerspelling)\n",
    "    \n",
    "    Parameters:\n",
    "        gesture_list: list of str\n",
    "            List of gestures to go through\n",
    "        examples: str (default \"Examples\")\n",
    "            Name of the folder with examples.\n",
    "        save: bool (default True)\n",
    "            Whether or not to save the captured images, i.e. whether or not to collect new data.\n",
    "            If True, legitimate directory for saving needs to be specified.\n",
    "        predict: bool (default False)\n",
    "            Whether or not to include prediction on the screen\n",
    "        data_directory: str\n",
    "            Name of the folder in which to save the images in case save is True.\n",
    "        current_amounts: dict of str: int pairs\n",
    "            Dictionary of current amounts of datapoints per each gesture. Only relevant in case save is True.\n",
    "        desired_amounts: dict of str: int pairs\n",
    "            Dictionary of desired amounts of datapoints per each gesture. Only relevant in case save is True.\n",
    "        gesture_paths: dict of str: str pairs\n",
    "            Dictionary of paths for each gesture. Only relevant in case save is True.\n",
    "        model: keras.engine.sequential.Sequential\n",
    "            Model that the user would like to use for prediction.\n",
    "    \"\"\"\n",
    "    # Input management\n",
    "    if not isinstance(gesture_list, list):\n",
    "        raise ValueError(\"Different datatype than list has been given as input for the list of gestures.\")\n",
    "    else:\n",
    "        for val in gesture_list:\n",
    "            if not isinstance(val, str):\n",
    "                raise ValueError(\"Different datatype than string has been given for one of the values in the list of gestures.\")\n",
    "        if len(gesture_list) != len(set(gesture_list)):\n",
    "            raise ValueError(\"There are some gesture duplicates in the list of gestures, please check.\")\n",
    "\n",
    "    if not isinstance(examples, str):\n",
    "        raise ValueError(\"Different datatype than string has been given for the name of the folder with examples.\")\n",
    "    else:\n",
    "        if not os.path.exists(examples):\n",
    "            raise ValueError(\"The given directory for the examples does not exist, please specify a correct directory path.\")\n",
    "        else:\n",
    "            files = os.listdir(examples)\n",
    "            if len(files) != len(gesture_list):\n",
    "                raise ValueError(\"The length of the example folder does not correspond to the list of gestures, please adjust.\")\n",
    "            gesture_names = [re.split(r\"[.]\", file)[0] for file in files]\n",
    "            if len(gesture_names) != len(set(gesture_names)):\n",
    "                raise ValueError(\"There are some gesture duplicates in the example folder, please check.\")\n",
    "            if set(gesture_names) != set(gesture_list):\n",
    "                raise ValueError(\"The list of gestures does not correspond to the files in the given example folder.\")\n",
    "\n",
    "    if not isinstance(save, bool):\n",
    "        raise ValueError(\"Different datatype than boolean has been given as input for the save parameter.\")\n",
    "\n",
    "    if save:\n",
    "        pass\n",
    "        # Deploy further input management for other parameters\n",
    "        # TODO !!!! \n",
    "\n",
    "    # The rectangle in the frame that is cropped from the web camera image \n",
    "    # (one for torso location, one for fingerspelling location)\n",
    "    rect_torso = create_rectangle((225, 275), 200, 200)\n",
    "    rect_fingerspell_1 = create_rectangle((50, 50), 200, 200)\n",
    "    rect_fingerspell_2 = create_rectangle((400, 50), 200, 200)\n",
    "    rect = rect_torso\n",
    "\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "    \n",
    "    # Encapsulate the whole process to be able to close cameras in case of error\n",
    "    try:\n",
    "\n",
    "        # Establish the windows and place them accordingly\n",
    "        cv2.namedWindow(\"Camera view\")\n",
    "        cv2.resizeWindow(\"Camera view\", 640, 480)\n",
    "        cv2.moveWindow(\"Camera view\", 15, 200)\n",
    "\n",
    "        cv2.namedWindow(\"Grayscale view\")\n",
    "        cv2.resizeWindow(\"Grayscale view\", 480, 360)\n",
    "        cv2.moveWindow(\"Grayscale view\", 655, 30)\n",
    "\n",
    "        cv2.namedWindow(\"Binary view\")\n",
    "        cv2.resizeWindow(\"Binary view\", 480, 360)\n",
    "        cv2.moveWindow(\"Binary view\", 655, 430)\n",
    "\n",
    "        cv2.namedWindow(\"Example\")\n",
    "        cv2.resizeWindow(\"Example\", 380, 270)\n",
    "        cv2.moveWindow(\"Example\", 1125, 280)\n",
    "\n",
    "        if predict:\n",
    "            gestures_folder = os.listdir(data_directory)\n",
    "\n",
    "        lang = True  # To let the user change language, True stands for English, False for Czech\n",
    "        rectangle_position = 0  # Which position of the rectangle to use\n",
    "\n",
    "        # Perform the data collecting process for each gesture in the given gesture list\n",
    "        for gesture in gesture_list:\n",
    "\n",
    "            # Initialize necessary variables (different per gesture)\n",
    "            # There is no limit on when to end during the process of not saving - has to be commanded manually\n",
    "            if save:\n",
    "                current = current_amounts[gesture] + 1\n",
    "                end = desired_amounts[gesture]\n",
    "            else:\n",
    "                current = 0\n",
    "                end = np.inf\n",
    "            counter = current\n",
    "            \n",
    "            flag = 0  # To know when a new gesture is being taken for the first time\n",
    "            exit = 0  # To let the user end the process early by clicking the \"Esc\" key\n",
    "\n",
    "            # Continue until the respective subfolder has the designated number of samples\n",
    "            while counter <= end:\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Check validity and avoid mirroring if frame is present\n",
    "                if not ret:\n",
    "                    print(\"There has been a problem retrieving your frame\")\n",
    "                    break\n",
    "                else:\n",
    "                    frame = cv2.flip(frame, 1)\n",
    "\n",
    "                # End the process for the current gesture in case the \"q\" key is hit\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == ord(\"q\"):\n",
    "                    break\n",
    "\n",
    "                # End the whole process in case the \"Esc\" key is hit\n",
    "                if key == ord(\"\\x1b\"):\n",
    "                    exit = 1\n",
    "                    break\n",
    "\n",
    "                # Change language settings in case the \"l\" key is hit\n",
    "                if key == ord(\"l\"):\n",
    "                    lang = not lang\n",
    "\n",
    "                # Change the rectangle position if the \"spacebar\" key is hit\n",
    "                if key == ord(\" \"):\n",
    "                    rectangle_position += 1\n",
    "                    rect = [rect_torso, rect_fingerspell_1, rect_fingerspell_2][rectangle_position % 3]\n",
    "\n",
    "                # Create grayscale version\n",
    "                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Binarize the grayscale image using adaptive thresholding\n",
    "                frame_binary = frame_gray[(rect[0][1] + 2):(rect[2][1] - 2), \n",
    "                                          (rect[0][0] + 2):(rect[1][0] - 2)]\n",
    "\n",
    "                # Preprocessing, denoising, blurring\n",
    "                frame_binary = cv2.fastNlMeansDenoising(frame_binary, None, 5, 15, 7)\n",
    "                frame_binary = cv2.medianBlur(frame_binary, 3)\n",
    "                frame_binary = cv2.GaussianBlur(frame_binary, (3, 3), 0)\n",
    "                # Adaptive thresholding\n",
    "                frame_binary = cv2.adaptiveThreshold(frame_binary, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                                     cv2.THRESH_BINARY_INV, 3, 2)\n",
    "                # Closing operation on the thresholded image\n",
    "                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "                frame_binary = cv2.morphologyEx(frame_binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "                # Show all images\n",
    "                \n",
    "                # Live view with frame and text\n",
    "                cv2.rectangle(frame, rect[0], rect[3], (0, 255, 0), 2)\n",
    "                # Add information about prediction if expected, otherwise just show the name of the gesture\n",
    "                if predict:\n",
    "                    prediction = model(np.expand_dims(np.expand_dims(cv2.resize(frame_binary, \n",
    "                                                                                (64, 64)), \n",
    "                                                                     axis=0), axis=-1), \n",
    "                                       training=False).numpy()\n",
    "                    txt = gestures_folder[np.argmax(prediction, axis=1)[0]]\n",
    "                else:\n",
    "                    txt = gesture.capitalize()\n",
    "                cv2.putText(frame, txt, (rect[0][0], rect[0][1] - 15), \n",
    "                            cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.imshow(\"Camera view\", frame)\n",
    "\n",
    "                # Grayscale version\n",
    "                cv2.imshow(\"Grayscale view\", cv2.resize(frame_gray, (480, 360)))\n",
    "\n",
    "                # Binary version\n",
    "                cv2.imshow(\"Binary view\", cv2.resize(frame_binary, (480, 360)))\n",
    "\n",
    "                # Show example on new gesture\n",
    "                if not flag:\n",
    "                    example = cv2.imread(f\"{os.path.join(examples, gesture)}\" + \".jpg\")\n",
    "                    cv2.imshow(\"Example\", cv2.resize(example, (380, 270)))\n",
    "                    flag = 1\n",
    "\n",
    "                # To reduce the number of almost identical frames, only save every n frames\n",
    "                # To give space for adjustments and \"learning\" a new sign, only start collecting after some time\n",
    "                if save:\n",
    "                    if not current % 2 and current > 90:\n",
    "\n",
    "                        # Create the naming for the file with the desired padding, i.e. (\"gesture_run-number.jpg\")\n",
    "                        img_name = gesture + \"_\" + str(counter) + \".jpg\"\n",
    "                        img_path = r\"%s\" % os.path.join(gesture_paths[gesture], img_name)\n",
    "\n",
    "                        # Save the cropped rectangle from the frame\n",
    "                        if not cv2.imwrite(img_path, \n",
    "                                           cv2.resize(frame_binary, (64, 64))):\n",
    "                            print(\"Something went wrong during this attempt:\",\n",
    "                                  f\"gesture - {gesture}, run - {counter}\")\n",
    "\n",
    "                        counter += 1\n",
    "\n",
    "                current += 1\n",
    "\n",
    "            if exit:\n",
    "                break\n",
    "\n",
    "    # Close the camera and all windows in case of unexpected fatality\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-8b264c977d17>:36: UserWarning: Given script directory is empty, thus all the processes will run in the location of this script.\n",
      "  warnings.warn(\"Given script directory is empty, thus all the processes will run in the location of this script.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder with this name already exists: Data\n",
      "A folder with this name already exists: Examples\n"
     ]
    }
   ],
   "source": [
    "# Specify the list of gestures, a subfolder will be created for each one\n",
    "gestures = [\"I index\", \"My\", \"You\", \"Your\",\n",
    "            \"In\", \"To\", \"With\", \"Yes\",\n",
    "            \"No\", \"Well\", \"I love you\", \"Oh I see\",\n",
    "            \"Name\", \"Hug\", \"Internet\", \"Bus\",\n",
    "            \"Money\", \"Work\", \"Ask\",\n",
    "            \"Go\", \"Look\", \"Have\", \"Correct\",\n",
    "            \"Want\", \"Where\", \n",
    "            \"A\", \"B\", \"C\", \"D\",\n",
    "            \"E\", \"F\", \"G\", \"H\",\n",
    "            \"I\", \"K\", \"L\", \"M\",\n",
    "            \"N\", \"O\", \"P\", \"Q\",\n",
    "            \"R\", \"S\", \"T\", \"U\",\n",
    "            \"V\", \"W\", \"X\", \"Y\"]\n",
    "\n",
    "script_dir = os.path.dirname(\"Image Collection.ipynb\")\n",
    "\n",
    "# Specify and set up the folder environment, amounts and paths for all the gestures in the gesture list\n",
    "data_dir, example_dir, desired_amount, current_amount, paths = setup_folders(script_dir, gestures, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2a4c7b56160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN.build_model(labels=49, convolutional_layers=4, input_shape=(64, 64))\n",
    "model.load_weights(\"Weights/weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "im = cv2.imread(\"Data/Yes/Yes_88.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im = np.expand_dims(im, axis=-1)\n",
    "prediction = model(im, training=False)\n",
    "os.listdir(\"Data\")[np.argmax(prediction, axis = 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test model collection, uncomment and run the lines below \n",
    "# Note that the \"desired_amount\" per gesture might be satisfied, thus the process will not run\n",
    "# In this case, re-run the above setup_folders function but raise the number of samples per gesture (now 500)\n",
    "\n",
    "#image_capturing(gestures, save=True, data_directory=data_dir, current_amounts=current_amount,\n",
    "#                desired_amounts=desired_amount, gesture_paths=paths)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# To test model showcasing, uncomment and run the lines below\n",
    "\n",
    "#image_capturing(gestures, save=False, predict=True, \n",
    "#                    data_directory=data_dir, current_amounts=current_amount, desired_amounts=desired_amount, \n",
    "#                    gesture_paths=paths, model=model)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# To test data collection script showcasing (no model prediction, no saving), uncomment and run the line below\n",
    "#image_capturing(gestures, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of some morphological operations I have experimented with (with no real success)\n",
    "\n",
    "#kernel = np.ones((5, 5), np.uint8)\n",
    "#kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "#frame_binary = cv2.morphologyEx(frame_binary, cv2.MORPH_GRADIENT, kernel)\n",
    "#frame_binary = cv2.erode(frame_binary, kernel, iterations=1)\n",
    "#frame_binary = cv2.dilate(frame_binary, kernel, iterations=1)\n",
    "#frame_binary = cv2.medianBlur(frame_binary, 3)\n",
    "#frame_binary = cv2.threshold(frame_gray, 150, 255, cv2.THRESH_BINARY)[1]\n",
    "#frame_binary = cv2.erode(frame_binary, kernel, iterations=3)\n",
    "#frame_binary = cv2.dilate(frame_binary, kernel, iterations=2)\n",
    "#frame_binary = cv2.morphologyEx(frame_binary, cv2.MORPH_GRADIENT, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to find contours in the binarized frame and add them to the original frame\n",
    "\n",
    "# Find contours and draw them into the original image\n",
    "#contours = cv2.findContours(frame_binary.copy(), \n",
    "#                            cv2.RETR_EXTERNAL, \n",
    "#                            cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "#if contours:\n",
    "#    cv2.drawContours(frame, \n",
    "#                     max(contours, key=cv2.contourArea) + rect[0], \n",
    "#                     -1, \n",
    "#                     (0, 0, 255), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old version of the function including two methods for thresholding\n",
    "\n",
    "old = \"\"\"\n",
    "\n",
    "def image_capturing(method=\"adaptive\", binary_threshold=0, last_mask=-1):\n",
    "    \"\"Capture image from the camera, convert it to grayscale \n",
    "    and then perform preprocessing and thresholding.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    method (string) -- hand segmentation method selection from (default adaptive)\n",
    "        mask = use background substraction based on mask taken at the beginning\n",
    "        adaptive = use adaptive thresholding methods\n",
    "    binary_thresh (integer) -- the thresholding parameter for binary thresholding in mask method (default 150)\n",
    "    last_mask (integer) -- the last frame to consider for the creation of background mask in mask method\n",
    "    \"\"\n",
    "    # Input management\n",
    "    if method not in [\"adaptive\", \"mask\"]:\n",
    "        raise ValueError(\"Method other than adaptive or mask has been given as input\")\n",
    "    \n",
    "    if not isinstance(binary_threshold, int):\n",
    "        raise ValueError(\"Different datatype than integer has been given as input for binary threshold\")\n",
    "    \n",
    "    if not isinstance(last_mask, int):\n",
    "        raise ValueError(\"Different datatype than integer has been given as input for last frame of background mask\")\n",
    "    \n",
    "    if method == \"mask\" and binary_threshold == 0:\n",
    "        wrn = \"\\nMask thresholding method has been chosen but binary threshold has not been specified.\"\n",
    "        wrn += \"\\nThis will result in a fully one-colored image, please specify the threshold\"\n",
    "        warnings.warn(wrn)\n",
    "\n",
    "    if method == \"mask\" and (binary_threshold < 0 or binary_threshold >= 255):\n",
    "        wrn = \"\\nMask thresholding method has been chosen but binary threshold is under 0 or over 255.\"\n",
    "        wrn += \"\\nThis will result in a fully one-colored image, please specify different threshold (between 1 and 254)\"\n",
    "        warnings.warn(wrn)\n",
    "\n",
    "    if method == \"mask\" and last_mask <= 10:\n",
    "        if last_mask == -1:\n",
    "            wrn = \"\\nBackground substraction thresholding method has been chosen but last mask frame has not been specified.\"\n",
    "        else:\n",
    "            wrn = \"\\nBackground substraction thresholding method has been chosen but last mask frame is very low (<= 10).\"\n",
    "        wrn += \"\\nThis may result in unpredictable behaviour and possibly crash of the whole script, please correct the parameter\"\n",
    "        warnings.warn(wrn)\n",
    "\n",
    "    # The rectangle in the frame that is cropped from the web camera image\n",
    "    rect = [(225, 275), (425, 275), \n",
    "            (225, 475), (425, 475)]\n",
    "\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "    # Encapsulate the whole process to be able to close cameras in case of error\n",
    "    try:\n",
    "\n",
    "        # Establish the windows and place them accordingly\n",
    "        cv2.namedWindow(\"Camera view\")\n",
    "        cv2.resizeWindow(\"Camera view\", 640, 480)\n",
    "        cv2.moveWindow(\"Camera view\", 15, 200)\n",
    "\n",
    "        cv2.namedWindow(\"Grayscale view\")\n",
    "        cv2.resizeWindow(\"Grayscale view\", 480, 360)\n",
    "        cv2.moveWindow(\"Grayscale view\", 655, 30)\n",
    "\n",
    "        cv2.namedWindow(\"Binary view\")\n",
    "        cv2.resizeWindow(\"Binary view\", 480, 360)\n",
    "        cv2.moveWindow(\"Binary view\", 655, 430)\n",
    "\n",
    "        cv2.namedWindow(\"Example\")\n",
    "        cv2.resizeWindow(\"Example\", 380, 270)\n",
    "        cv2.moveWindow(\"Example\", 1125, 280)\n",
    "\n",
    "        # Initialize variables for background substraction\n",
    "        frame_count = 0\n",
    "        background = None\n",
    "\n",
    "        # Perform the data collecting process for each gesture in the given gesture list\n",
    "        for gesture in gestures:\n",
    "\n",
    "            # Initialize necessary variables (different per gesture)\n",
    "            current = current_amount[gesture] + 1\n",
    "            counter = current\n",
    "            end = desired_amount[gesture]\n",
    "            flag = 0 # To know when a new gesture is being taken for the first time\n",
    "            exit = 0 # To let the user end the process early by clicking the \"Esc\" key\n",
    "\n",
    "            # Continue until the respective subfolder has the designated number of samples\n",
    "            while counter <= end:\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Check validity and avoid mirroring if frame is present\n",
    "                if not ret:\n",
    "                    print(\"There has been a problem retrieving your frame\")\n",
    "                    break\n",
    "                else:\n",
    "                    frame_count += 1\n",
    "                    frame = cv2.flip(frame, 1)\n",
    "\n",
    "                # End the process for the current gesture in case the \"q\" key is hit\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == ord(\"q\"):\n",
    "                    break\n",
    "\n",
    "                # End the whole process in case the \"Esc\" key is hit\n",
    "                if key == ord(\"\\x1b\"):\n",
    "                    exit = 1\n",
    "                    break\n",
    "\n",
    "                # Create grayscale version\n",
    "                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Binarize the grayscale image using thresholding (with various methods)\n",
    "                frame_binary = frame_gray[(rect[0][1] + 2):(rect[2][1] - 2), \n",
    "                                          (rect[0][0] + 2):(rect[1][0] - 2)]\n",
    "                \n",
    "                # Version using background mask\n",
    "                if method == \"mask\":\n",
    "                    # Create mask for the background\n",
    "                    if background is None:\n",
    "                        background = frame_binary.copy().astype(\"float\")\n",
    "                    else:\n",
    "                        if frame_count <= last_mask:\n",
    "                            background = cv2.accumulateWeighted(frame_binary, background, 0.5)\n",
    "                        # Use the mask for background substraction\n",
    "                        else:\n",
    "                            frame_binary = cv2.absdiff(background.astype(\"uint8\"), frame_binary)\n",
    "                            frame_binary = cv2.GaussianBlur(frame_binary, (3, 3), 0)\n",
    "                            frame_binary = cv2.threshold(frame_binary, binary_threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "                # Version using adaptive thresholding\n",
    "                elif method == \"adaptive\":\n",
    "                    # Preprocessing, denoising, blurring\n",
    "                    frame_binary = cv2.fastNlMeansDenoising(frame_binary, None, 5, 15, 7)\n",
    "                    frame_binary = cv2.medianBlur(frame_binary, 3)\n",
    "                    frame_binary = cv2.GaussianBlur(frame_binary, (3, 3), 0)\n",
    "                    # Adaptive thresholding\n",
    "                    frame_binary = cv2.adaptiveThreshold(frame_binary, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                                         cv2.THRESH_BINARY_INV, 3, 2)\n",
    "                    # Closing operation on the thresholded image\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "                    frame_binary = cv2.morphologyEx(frame_binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "                # Show all images\n",
    "                \n",
    "                # Live view with frame and text\n",
    "                cv2.rectangle(frame, rect[0], rect[3], (0, 255, 0), 2)\n",
    "                #acc = 0.0\n",
    "                #txt = gesture.capitalize() + f\" ({str(round(acc, 2))} %)\"      # in preparation for model version\n",
    "                txt = gesture.capitalize()\n",
    "                cv2.putText(frame, txt, (rect[0][0], rect[0][1] - 15), \n",
    "                            cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.imshow(\"Camera view\", frame)\n",
    "\n",
    "                # Grayscale version\n",
    "                cv2.imshow(\"Grayscale view\", cv2.resize(frame_gray, (480, 360)))\n",
    "\n",
    "                # Binary version\n",
    "                if frame_count > last_mask:\n",
    "                    cv2.imshow(\"Binary view\", cv2.resize(frame_binary, (480, 360)))\n",
    "\n",
    "                # Show example on new gesture\n",
    "                if not flag:\n",
    "                    example = cv2.imread(f\"{os.path.join(example_dir, gesture)}\" + \".jpg\")\n",
    "                    cv2.imshow(\"Example\", cv2.resize(example, (380, 270)))\n",
    "                    #time.sleep(1)\n",
    "                    flag = 1\n",
    "\n",
    "                # To reduce the number of almost identical frames, only save every n frames\n",
    "                # To give space for adjustments and \"learning\" a new sign, only start collecting after some time\n",
    "                if not current % 2 and current > 90:\n",
    "\n",
    "                    # Create the naming for the file with the desired padding, i.e. (\"gesture_run-number.jpg\")\n",
    "                    img_name = gesture + \"_\" + str(counter) + \".jpg\"\n",
    "                    img_path = r\"%s\" %os.path.join(paths[gesture], img_name)\n",
    "\n",
    "                    # Save the cropped rectangle from the frame\n",
    "                    if not cv2.imwrite(img_path, \n",
    "                                       frame_binary):\n",
    "                        print(\"Something went wrong during this attempt:\",\n",
    "                              f\"gesture - {gesture}, run - {counter}\")\n",
    "\n",
    "                    counter += 1\n",
    "\n",
    "                current += 1\n",
    "\n",
    "            if exit:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "\n",
    "    # Close the camera and all windows in case of unexpected fatality\n",
    "    except:\n",
    "        print(\"A fatality has occured, the program will now terminate\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
