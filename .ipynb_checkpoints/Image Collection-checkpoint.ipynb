{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps: Switch while and for loops for new approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.dirname(\"Image Collection.ipynb\")\n",
    "data_dir = os.path.join(script_dir, \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the list of gestures, a subfolder will be created for each one\n",
    "gestures = [\"1\", \"2\", \"3\", \"A\", \"B\"]\n",
    "\n",
    "# Specify the desired number of images for each gesture\n",
    "desired_amount = {\"1\": 20, \"2\": 20, \"3\": 20, \"A\": 10, \"B\": 10}\n",
    "\n",
    "# Initialize the dictionary of current number of occurrences per each gesture\n",
    "current_amount = {gesture: 0 for gesture in gestures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data folder if it does not exist yet\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "\n",
    "for gesture in gestures:\n",
    "    \n",
    "    # Create a subfolder per each gesture if it does not exist yet\n",
    "    new = os.path.join(data_dir, gesture)\n",
    "    if not os.path.exists(new):\n",
    "        os.makedirs(new)\n",
    "        \n",
    "    # If the subfolder exists, make sure that the ordering is correct and\n",
    "    # shift it if any skips are present\n",
    "    # (e.g. \"A_1.jpg\", \"A_2.jpg\", ... instead of \"A_1.jpg\", \"A_3.jpg\", ...)\n",
    "    else:\n",
    "        files = os.listdir(new)\n",
    "        files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "        l = len(files)\n",
    "        \n",
    "        # Go through each file and if the run order skips a count, shift the respective file's run order\n",
    "        for i in range(l - 1):\n",
    "            name_split = re.split(r\"[_|.]\", files[i])\n",
    "            name_split_next = re.split(r\"[_|.]\", files[i + 1])\n",
    "            if (int(name_split[1]) + 1) != int(name_split_next[1]):\n",
    "                new_name = name_split[0] + \"_\" + str(int(name_split[1]) + 1) + \".\" + name_split[2]\n",
    "                os.rename(os.path.join(new, files[i + 1]), os.path.join(new, new_name))\n",
    "                files = os.listdir(new)\n",
    "                files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "            \n",
    "        # Since the gesture subfolder is sorted by padding, we can use the last element as the current run\n",
    "        current_amount[gesture] = 0 if not files else int(re.split(r\"[_|.]\", files[-1])[1])\n",
    "\n",
    "paths = {gesture: os.path.join(data_dir, gesture) for gesture in gestures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rectangle in the frame that is cropped from the web camera image\n",
    "rect = [(225, 275), (425, 275), \n",
    "       (225, 475), (425, 475)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Perform the data collecting process for each gesture in the given gesture list\n",
    "for gesture in gestures:\n",
    "    \n",
    "    current = current_amount[gesture] + 1\n",
    "    counter = current\n",
    "    end = desired_amount[gesture]\n",
    "    flag = 0\n",
    "    exit = 0\n",
    "    \n",
    "    # Continue until the respective subfolder has the designated number of samples\n",
    "    while counter <= end:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.rectangle(frame, rect[0], rect[3], (0, 255, 0), 2)\n",
    "        \n",
    "        # Check validity\n",
    "        if not ret:\n",
    "            print(\"There has been a problem retrieving your frame\")\n",
    "            break\n",
    "        \n",
    "        # End the process for the current gesture in case the \"q\" key is hit\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        \n",
    "        # End the whole process in case the \"Esc\" key is hit\n",
    "        if key == ord(\"\\x1b\"):\n",
    "            exit = 1\n",
    "            break\n",
    "            \n",
    "        # Create grayscale version(s)\n",
    "        frame_gray_gleam = (np.average((frame/255)**(1/2.2), axis=2)*255).astype(np.uint8)\n",
    "        frame_gray_luminance = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # frame_gray_gleam - create correct approach for gamme correction using mask table and opencv LUT function\n",
    "        \n",
    "        # Binarize these version(s) using thresholding\n",
    "        frame_binary_luminance = cv2.adaptiveThreshold(frame_gray_luminance, 1, \n",
    "                                                       cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 2)\n",
    "        frame_binary_gleam = cv2.adaptiveThreshold(frame_gray_luminance, 1, \n",
    "                                                   cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 2)\n",
    "        \n",
    "        # Show all images\n",
    "        # Live view with frame and text\n",
    "        cv2.imshow(\"Real-time view\", frame)\n",
    "        #cv2.putText(frame, text=f\"{gesture.capitalize()}\", org=(rect[0][0], rect[0][1]), \n",
    "#                    font=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, color=(0, 255, 0), thickness=2)\n",
    "        \n",
    "        # Grayscale version(s)\n",
    "        cv2.imshow(\"Grayscale (luminance) view\", frame_gray_luminance)\n",
    "        cv2.imshow(\"Grayscale (gleam) view\", frame_gray_gleam)\n",
    "        \n",
    "        # Binary version(s)\n",
    "        cv2.imshow(\"Binary (luminance) view\", frame_binary_luminance)\n",
    "        cv2.imshow(\"Binary (gleam) view\", frame_binary_gleam)\n",
    "        \n",
    "        if not flag:\n",
    "            time.sleep(10)\n",
    "        flag = 1\n",
    "            \n",
    "        # To reduce the number of almost identical frames, only save every n frames\n",
    "        if not current % 4:\n",
    "        \n",
    "            # Create the naming for the file with the desired padding, i.e. (\"gesture_run.jpg\")\n",
    "            img_name = gesture + \"_\" + str(counter) + \".jpg\"\n",
    "            img_path = r\"%s\" %os.path.join(paths[gesture], img_name)\n",
    "\n",
    "            # Save the cropped rectangle from the frame\n",
    "            if not cv2.imwrite(img_path, \n",
    "                               frame[(rect[0][1] + 2):(rect[2][1] - 2), \n",
    "                                     (rect[0][0] + 2):(rect[1][0] - 2)]):\n",
    "                print(\"Something went wrong during this attempt:\",\n",
    "                      f\"gesture - {gesture}, run - {counter}\")\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "        if exit:\n",
    "            break\n",
    "            \n",
    "        current += 1\n",
    "\n",
    "    # Close all the windows for the respective gesture\n",
    "    if flag:\n",
    "        cv2.destroyWindow(gesture.capitalize())\n",
    "        cv2.destroyWindow(f\"{gesture.capitalize()} grayscale (luminance)\")\n",
    "        cv2.destroyWindow(f\"{gesture.capitalize()} grayscale (gleam)\")\n",
    "        cv2.destroyWindow(f\"{gesture.capitalize()} binary (luminance)\")\n",
    "        cv2.destroyWindow(f\"{gesture.capitalize()} binary (gleam)\")\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some necessary variables\n",
    "current = current_amount[gesture] + 1\n",
    "counter = current\n",
    "end = desired_amount[gesture]\n",
    "flag = 0\n",
    "exit = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Continue until the respective subfolder has the designated number of samples\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.rectangle(frame, rect[0], rect[3], (0, 255, 0), 2)\n",
    "\n",
    "    # Check validity\n",
    "    if not ret:\n",
    "        print(\"There has been a problem retrieving your frame\")\n",
    "        break\n",
    "\n",
    "    # End the process for the current gesture in case the \"q\" key is hit\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    # End the whole process in case the \"Esc\" key is hit\n",
    "    if key == ord(\"\\x1b\"):\n",
    "        exit = 1\n",
    "        break\n",
    "    \n",
    "    # Create grayscale version(s)\n",
    "    frame_gray_gleam = (np.average((frame/255)**(1/2.2), axis=2)*255).astype(np.uint8)\n",
    "    frame_gray_luminance = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # frame_gray_gleam - create correct approach for gamme correction using mask table and opencv LUT function\n",
    "\n",
    "    # Binarize these version(s) using thresholding\n",
    "    frame_binary_luminance = cv2.adaptiveThreshold(frame_gray_luminance, 1, \n",
    "                                                   cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 2)\n",
    "    frame_binary_gleam = cv2.adaptiveThreshold(frame_gray_luminance, 1, \n",
    "                                               cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 2)\n",
    "\n",
    "    # Show all images\n",
    "    # Live view with frame and text\n",
    "    cv2.imshow(\"Real-time view\", frame)\n",
    "    #cv2.putText(frame, text=f\"{gesture.capitalize()}\", org=(rect[0][0], rect[0][1]), \n",
    "#                    font=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    # Grayscale version(s)\n",
    "    cv2.imshow(\"Grayscale (luminance) view\", frame_gray_luminance)\n",
    "    cv2.imshow(\"Grayscale (gleam) view\", frame_gray_gleam)\n",
    "\n",
    "    # Binary version(s)\n",
    "    cv2.imshow(\"Binary (luminance) view\", frame_binary_luminance)\n",
    "    cv2.imshow(\"Binary (gleam) view\", frame_binary_gleam)\n",
    "    \n",
    "    for gesture in gestures:\n",
    "\n",
    "# Perform the data collecting process for each gesture in the given gesture list\n",
    "for gesture in gestures:\n",
    "    \n",
    "    current = current_amount[gesture] + 1\n",
    "    counter = current\n",
    "    end = desired_amount[gesture]\n",
    "    flag = 0\n",
    "    exit = 0\n",
    "    \n",
    "    # Continue until the respective subfolder has the designated number of samples\n",
    "    while counter <= end:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.rectangle(frame, rect[0], rect[3], (0, 255, 0), 2)\n",
    "        \n",
    "        # Check validity\n",
    "        if not ret:\n",
    "            print(\"There has been a problem retrieving your frame\")\n",
    "            break\n",
    "        \n",
    "        # End the process for the current gesture in case the \"q\" key is hit\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        \n",
    "        # End the whole process in case the \"Esc\" key is hit\n",
    "        if key == ord(\"\\x1b\"):\n",
    "            exit = 1\n",
    "            break\n",
    "            \n",
    "        # Create grayscale version(s)\n",
    "        frame_gray_gleam = (np.average((frame/255)**(1/2.2), axis=2)*255).astype(np.uint8)\n",
    "        frame_gray_luminance = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # frame_gray_gleam - create correct approach for gamme correction using mask table and opencv LUT function\n",
    "        \n",
    "        # Binarize these version(s) using thresholding\n",
    "        frame_binary_luminance = cv2.adaptiveThreshold(frame_gray_luminance, 1, \n",
    "                                                       cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 2)\n",
    "        frame_binary_gleam = cv2.adaptiveThreshold(frame_gray_luminance, 1, \n",
    "                                                   cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 2)\n",
    "        \n",
    "        # Show all images\n",
    "        # Live view with frame and text\n",
    "        cv2.imshow(\"Real-time view\", frame)\n",
    "        #cv2.putText(frame, text=f\"{gesture.capitalize()}\", org=(rect[0][0], rect[0][1]), \n",
    "#                    font=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, color=(0, 255, 0), thickness=2)\n",
    "        \n",
    "        # Grayscale version(s)\n",
    "        cv2.imshow(\"Grayscale (luminance) view\", frame_gray_luminance)\n",
    "        cv2.imshow(\"Grayscale (gleam) view\", frame_gray_gleam)\n",
    "        \n",
    "        # Binary version(s)\n",
    "        cv2.imshow(\"Binary (luminance) view\", frame_binary_luminance)\n",
    "        cv2.imshow(\"Binary (gleam) view\", frame_binary_gleam)\n",
    "        \n",
    "        if not flag:\n",
    "            time.sleep(10)\n",
    "        flag = 1\n",
    "            \n",
    "        # To reduce the number of almost identical frames, only save every n frames\n",
    "        if not current % 4:\n",
    "        \n",
    "            # Create the naming for the file with the desired padding, i.e. (\"gesture_run.jpg\")\n",
    "            img_name = gesture + \"_\" + str(counter) + \".jpg\"\n",
    "            img_path = r\"%s\" %os.path.join(paths[gesture], img_name)\n",
    "\n",
    "            # Save the cropped rectangle from the frame\n",
    "            if not cv2.imwrite(img_path, \n",
    "                               frame[(rect[0][1] + 2):(rect[2][1] - 2), \n",
    "                                     (rect[0][0] + 2):(rect[1][0] - 2)]):\n",
    "                print(\"Something went wrong during this attempt:\",\n",
    "                      f\"gesture - {gesture}, run - {counter}\")\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "        if exit:\n",
    "            break\n",
    "            \n",
    "        current += 1\n",
    "\n",
    "    # Close all the windows for the respective gesture\n",
    "    if flag:\n",
    "        cv2.destroyWindow(gesture.capitalize())\n",
    "        cv2.destroyWindow(f\"{gesture.capitalize()} grayscale (luminance)\")\n",
    "        cv2.destroyWindow(f\"{gesture.capitalize()} grayscale (gleam)\")\n",
    "        cv2.destroyWindow(f\"{gesture.capitalize()} binary (luminance)\")\n",
    "        cv2.destroyWindow(f\"{gesture.capitalize()} binary (gleam)\")\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
