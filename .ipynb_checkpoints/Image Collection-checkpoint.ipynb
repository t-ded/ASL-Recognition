{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps: Switch while and for loops for new approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.dirname(\"Image Collection.ipynb\")\n",
    "data_dir = os.path.join(script_dir, \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the list of gestures, a subfolder will be created for each one\n",
    "gestures = [\"1\", \"2\", \"3\", \"A\", \"B\"]\n",
    "\n",
    "# Specify the desired number of images for each gesture\n",
    "desired_amount = {\"1\": 200, \"2\": 200, \"3\": 200, \"A\": 100, \"B\": 100}\n",
    "\n",
    "# Initialize the dictionary of current number of occurrences per each gesture\n",
    "current_amount = {gesture: 0 for gesture in gestures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data folder if it does not exist yet\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "\n",
    "for gesture in gestures:\n",
    "    \n",
    "    # Create a subfolder per each gesture if it does not exist yet\n",
    "    new = os.path.join(data_dir, gesture)\n",
    "    if not os.path.exists(new):\n",
    "        os.makedirs(new)\n",
    "        \n",
    "    # If the subfolder exists, make sure that the ordering is correct and\n",
    "    # shift it if any skips are present\n",
    "    # (e.g. \"A_1.jpg\", \"A_2.jpg\", ... instead of \"A_1.jpg\", \"A_3.jpg\", ...)\n",
    "    else:\n",
    "        files = os.listdir(new)\n",
    "        files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "        l = len(files)\n",
    "        \n",
    "        # Go through each file and if the run order skips a count, shift the respective file's run order\n",
    "        for i in range(l - 1):\n",
    "            name_split = re.split(r\"[_|.]\", files[i])\n",
    "            name_split_next = re.split(r\"[_|.]\", files[i + 1])\n",
    "            if (int(name_split[1]) + 1) != int(name_split_next[1]):\n",
    "                new_name = name_split[0] + \"_\" + str(int(name_split[1]) + 1) + \".\" + name_split[2]\n",
    "                os.rename(os.path.join(new, files[i + 1]), os.path.join(new, new_name))\n",
    "                files = os.listdir(new)\n",
    "                files.sort(key=lambda file: int(re.split(r\"[_|.]\", file)[1]))\n",
    "            \n",
    "        # Since the gesture subfolder is sorted by padding, we can use the last element as the current run\n",
    "        current_amount[gesture] = 0 if not files else int(re.split(r\"[_|.]\", files[-1])[1])\n",
    "\n",
    "paths = {gesture: os.path.join(data_dir, gesture) for gesture in gestures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rectangle in the frame that is cropped from the web camera image\n",
    "rect = [(225, 275), (425, 275), \n",
    "       (225, 475), (425, 475)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "# Encapsulate the whole process to be able to close cameras in case of error\n",
    "try:\n",
    "    \n",
    "    # Establish the windows and place them accordingly\n",
    "    cv2.namedWindow(\"Camera view\")\n",
    "    cv2.resizeWindow(\"Camera view\", 640, 480)\n",
    "    cv2.moveWindow(\"Camera view\", 15, 200)\n",
    "\n",
    "    cv2.namedWindow(\"Grayscale view\")\n",
    "    cv2.resizeWindow(\"Grayscale view\", 480, 360)\n",
    "    cv2.moveWindow(\"Grayscale view\", 655, 30)\n",
    "\n",
    "    cv2.namedWindow(\"Binary view\")\n",
    "    cv2.resizeWindow(\"Binary view\", 480, 360)\n",
    "    cv2.moveWindow(\"Binary view\", 655, 430)\n",
    "\n",
    "    cv2.namedWindow(\"Example\")\n",
    "    cv2.resizeWindow(\"Example\", 380, 270)\n",
    "    cv2.moveWindow(\"Example\", 1125, 280)\n",
    "\n",
    "    # Perform the data collecting process for each gesture in the given gesture list\n",
    "    for gesture in gestures:\n",
    "\n",
    "        current = current_amount[gesture] + 1\n",
    "        counter = current\n",
    "        end = desired_amount[gesture]\n",
    "        flag = 0\n",
    "        exit = 0\n",
    "\n",
    "        # Continue until the respective subfolder has the designated number of samples\n",
    "        while counter <= end:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Check validity\n",
    "            if not ret:\n",
    "                print(\"There has been a problem retrieving your frame\")\n",
    "                break\n",
    "\n",
    "            # End the process for the current gesture in case the \"q\" key is hit\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "            # End the whole process in case the \"Esc\" key is hit\n",
    "            if key == ord(\"\\x1b\"):\n",
    "                exit = 1\n",
    "                break\n",
    "\n",
    "            # Create grayscale version(s)\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Binarize these version(s) using thresholding\n",
    "            frame_binary = cv2.adaptiveThreshold(frame_gray, 255, \n",
    "                                                           cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 2)\n",
    "            frame_binary = cv2.threshold(frame_gray, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "            # Show all images\n",
    "            # Live view with frame and text\n",
    "            cv2.rectangle(frame, rect[0], rect[3], (0, 255, 0), 2)\n",
    "            #acc = 0.0\n",
    "            #txt = gesture.capitalize() + f\" ({str(round(acc, 2))} %)\"      # in preparation for model version\n",
    "            txt = gesture.capitalize()\n",
    "            cv2.putText(frame, txt, (rect[0][0], rect[0][1] - 15), \n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Camera view\", frame)\n",
    "\n",
    "            # Grayscale version(s)\n",
    "            cv2.imshow(\"Grayscale view\", cv2.resize(frame_gray, (480, 360)))\n",
    "\n",
    "            # Binary version(s)\n",
    "            cv2.imshow(\"Binary view\", cv2.resize(frame_binary, (480, 360)))\n",
    "\n",
    "            if not flag:\n",
    "                time.sleep(1)\n",
    "            flag = 1\n",
    "\n",
    "            # To reduce the number of almost identical frames, only save every n frames\n",
    "            if not current % 4:\n",
    "\n",
    "                # Create the naming for the file with the desired padding, i.e. (\"gesture_run-number.jpg\")\n",
    "                img_name = gesture + \"_\" + str(counter) + \".jpg\"\n",
    "                img_path = r\"%s\" %os.path.join(paths[gesture], img_name)\n",
    "\n",
    "                # Save the cropped rectangle from the frame\n",
    "                if not cv2.imwrite(img_path, \n",
    "                                   frame_binary[(rect[0][1] + 2):(rect[2][1] - 2), \n",
    "                                                (rect[0][0] + 2):(rect[1][0] - 2)]):\n",
    "                    print(\"Something went wrong during this attempt:\",\n",
    "                          f\"gesture - {gesture}, run - {counter}\")\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "            current += 1\n",
    "\n",
    "        if exit:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Close the camera and all windows in case of unexpected fatality\n",
    "except:\n",
    "    print(\"A fatality has occured, the program will now terminate\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
