Preprocessing pipeline:
Model: "preprocessing_pipeline"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 preprocessing_input (InputL  [(None, 196, 196, 3)]    0         
 ayer)                                                           
                                                                 
 grayscale (Grayscale)       (None, 196, 196, 1)       0         
                                                                 
 rescaling (Rescaling)       (None, 196, 196, 1)       0         
                                                                 
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
_________________________________________________________________


Trainable summary:
Model: "trainable_layers"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 trainable_input (InputLayer  [(None, 196, 196, 1)]    0         
 )                                                               
                                                                 
 conv2d (Conv2D)             (None, 65, 65, 64)        640       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 32, 32, 64)       0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 10, 10, 64)        36928     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         
 2D)                                                             
                                                                 
 batch_normalization (BatchN  (None, 5, 5, 64)         256       
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 5, 5, 64)          0         
                                                                 
 flatten (Flatten)           (None, 1600)              0         
                                                                 
 dense (Dense)               (None, 512)               819712    
                                                                 
 softmax_output (Dense)      (None, 49)                25137     
                                                                 
=================================================================
Total params: 882,673
Trainable params: 882,545
Non-trainable params: 128
_________________________________________________________________



Training parameters: {'verbose': 1, 'epochs': 36, 'steps': 134}
Final training accuracy: 0.971971869468689
Final validation accuracy: 0.9652919769287109
Final training precision: 0.9943919777870178
Final validation precision: 0.9892377853393555
Final training recall: 0.8998454213142395
Final validation recall: 0.9132979512214661
Final training f1_score: 
0.9719758033752441
Final validation f1_score: 
0.9653531312942505


Command line arguments: 
config_dir: 
collect: False
preprocess: False
train: True
showcase: False
predict: False
experiment: -1
tensorboard: True
early_stopping: disable
augmentation: True
randaugment: None
batch_size: 256
epochs: 36
optimizer: SGD
learning_rate: 0.01
lr_decay: 0.85
lr_decay_iterations: 10000
momentum: 0.95
weight_decay: 0.0001
label_smoothing: 0.1
seed: 123
split: 0.3
architecture: I,C-f64-k3-s3,P-tm-p2-s2,C-f64-k3-s3,P-tm-p2-s2,B,F,H-512,O
preprocessing_layers: I,G,R
