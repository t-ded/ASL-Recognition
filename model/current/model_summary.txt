Preprocessing pipeline:
Model: "preprocessing_pipeline"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 preprocessing_input (InputL  [(None, 196, 196, 3)]    0         
 ayer)                                                           
                                                                 
 grayscale (Grayscale)       (None, 196, 196, 1)       0         
                                                                 
 adaptive_thresholding (Adap  (None, 196, 196, 1)      0         
 tiveThresholding)                                               
                                                                 
 rescaling (Rescaling)       (None, 196, 196, 1)       0         
                                                                 
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
_________________________________________________________________


Trainable summary:
Model: "trainable_layers"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 trainable_input (InputLayer  [(None, 196, 196, 1)]    0         
 )                                                               
                                                                 
 conv2d (Conv2D)             (None, 192, 192, 128)     3328      
                                                                 
 max_pooling2d (MaxPooling2D  (None, 48, 48, 128)      0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 44, 44, 256)       819456    
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 11, 11, 256)      0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 30976)             0         
                                                                 
 dense (Dense)               (None, 256)               7929856   
                                                                 
 batch_normalization (BatchN  (None, 256)              1024      
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 256)               0         
                                                                 
 softmax_output (Dense)      (None, 49)                12593     
                                                                 
=================================================================
Total params: 8,766,257
Trainable params: 8,765,745
Non-trainable params: 512
_________________________________________________________________



Training parameters: {'verbose': 1, 'epochs': 30, 'steps': 510}
Final training accuracy: 0.9356192946434021
Final validation accuracy: 0.9777626991271973
Final training precision: 0.963410496711731
Final validation precision: 0.9842992424964905
Final training recall: 0.9185818433761597
Final validation recall: 0.9727217555046082
Final training f1_score: 
0.935704231262207
Final validation f1_score: 
0.9778944253921509


Command line arguments: 
config_dir: 
collect: False
preprocess: False
train: True
showcase: False
predict: False
guided: False
experiment: 61
tensorboard: True
early_stopping: loss
disable_checkpoint: True
seed: 123
split: 0.3
augmentation: False
randaugment: 10,3
batch_size: 128
epochs: 30
optimizer: SGD
learning_rate: 0.01
lr_decay: 1
lr_decay_iterations: 10000
momentum: 0.95
weight_decay: 0.0003
label_smoothing: 0
architecture: I,C-k5-f128-s1,P-tm-p3-s4,C-k5-f256-s1,P-tm-p3-s4,H-256,B,O
preprocessing_layers: I,G,T-tm-b7-c(3),R
