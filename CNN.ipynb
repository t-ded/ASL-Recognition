{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(labels, convolutional_layers=2, pooling_layers=True, input_shape=None):\n",
    "    \"\"\"\n",
    "    Creates a simple convolutional network by adding layers based on input\n",
    "    \n",
    "    Parameters:\n",
    "        labels: int\n",
    "            Number of layers for prediction (i.e. size of output layer of the model). Should be positive and higher than 1.\n",
    "        convolutional_layers: int (default 2)\n",
    "            Number of convolutional layers (using tensorflows Conv2D, including the input convolutional layer). Should be positive.\n",
    "        pooling_layers: bool (default True)\n",
    "            Whether to include pooling layers between every pair of convolutional layers\n",
    "        input_shape: (int, int, int) or (int, int) or None (default None):\n",
    "            Shape of the image that will be given as input (i.e. input shape of the first layer).\n",
    "            Integers in the tuple are required to be positive.\n",
    "\n",
    "    Returns:\n",
    "        model: keras.engine.sequential.Sequential\n",
    "            Model created according to input\n",
    "    \"\"\"\n",
    "    # Input management\n",
    "    if not isinstance(labels, int):\n",
    "        raise ValueError(\"Different datatype than integer has been given as input for the number of labels\")\n",
    "    \n",
    "    if not isinstance(convolutional_layers, int):\n",
    "        raise ValueError(\"Different datatype than integer has been given as input for the number of convolutional layers\")\n",
    "\n",
    "    if labels < 1:\n",
    "        raise ValueError(\"Number of labels is less than 1. Please specify different amount.\")\n",
    "\n",
    "    if labels == 1:\n",
    "        wrn = \"\\nYou have entered 1 as the number of labels.\\n\" \n",
    "        wrn += \"This might result in unpredicted behaviour and there is not much point in building a model then\"\n",
    "        warnings.warn(wrn)\n",
    "\n",
    "    if convolutional_layers < 1:\n",
    "        raise ValueError(\"This function expects at least one convolutional layer to be present in the model.\")\n",
    "\n",
    "    if not isinstance(pooling_layers, bool):\n",
    "        raise ValueError(\"Different datatype than boolean has been given as input for the pooling_layers parameter\")\n",
    "\n",
    "    if input_shape:\n",
    "        if not isinstance(input_shape, tuple):\n",
    "            raise ValueError(\"Input shape has been assigned and different input than tuple was given\")\n",
    "        if len(input_shape) not in [2, 3]:\n",
    "            raise ValueError(\"2D or 3D images expected as input\")\n",
    "        elif len(input_shape) == 2:\n",
    "            input_shape = tuple([*input_shape, 1])\n",
    "        for val in input_shape:\n",
    "            if not isinstance(val, int):\n",
    "                raise ValueError(\"Integers were expected in place of image dimensions in parameter input_shape\")\n",
    "            if val < 0:\n",
    "                raise ValueError(\"One of the dimensions of the input shape given is negative. Please give correct input shape.\")\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    if input_shape:\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape))\n",
    "    else:\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    for _ in range(convolutional_layers - 1):\n",
    "        if pooling_layers:\n",
    "            model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(layers.Dense(labels))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.dirname(\"Image Collection.ipynb\")\n",
    "data_dir = os.path.join(script_dir, \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = [\"I\", \"My\", \"You\", \"Your\", \n",
    "            \"In\", \"To\", \"With\", \"Yes\", \n",
    "            \"No\", \"Well\", \"I love you\",\n",
    "            \"Oh I see\", \"Name\", \"Hug\",\n",
    "            \"Internet\", \"Bus\", \"Money\",\n",
    "            \"Work\", \"Ask\", \"Go\",\n",
    "            \"Look\", \"Have\", \"Correct\",\n",
    "            \"Want\", \"Where\", \n",
    "            \"A\", \"B\", \"C\", \"D\", \n",
    "            \"E\", \"F\", \"G\", \"H\", \n",
    "            \"I\", \"K\", \"L\", \"M\", \n",
    "            \"N\", \"O\", \"P\", \"Q\", \n",
    "            \"R\", \"S\", \"T\", \"U\", \n",
    "            \"V\", \"W\", \"X\", \"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.keras.preprocessing.image_dataset_from_directory(data_dir,\n",
    "                                                                   validation_split=0.25,\n",
    "                                                                  subset=\"training\",\n",
    "                                                                  seed=123,\n",
    "                                                                  image_size=(128, 128),\n",
    "                                                                  color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.keras.preprocessing.image_dataset_from_directory(data_dir,\n",
    "                                                                   validation_split=0.25,\n",
    "                                                                  subset=\"validation\",\n",
    "                                                                  seed=123,\n",
    "                                                                  image_size=(128, 128),\n",
    "                                                                  color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(labels=49, convolutional_layers=2, input_shape=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_images, batch_size=200, epochs=11, \n",
    "                    validation_data=(test_images), steps_per_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "im = cv2.imread(\"Data/Yes/Yes_88.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im = np.expand_dims(im, axis=-1)\n",
    "prediction = model(im, training=False)\n",
    "os.listdir(\"Data\")[np.argmax(prediction, axis = 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"Weights/weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"Data/Yes/Yes_88.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im = np.expand_dims(im, axis=-1)\n",
    "prediction = model(im, training=False)\n",
    "os.listdir(\"Data\")[np.argmax(prediction, axis = 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = fig.get_figure()    \n",
    "figure.savefig(\"training.png\", dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "df.drop(columns=[\"val_loss\", \"loss\"], inplace=True)\n",
    "\n",
    "plt.figure(figsize=(15, 10), facecolor=(1, 1, 1))\n",
    "\n",
    "fig = sb.lineplot(data=df, sizes=[1.7, 1.7])\n",
    "plt.title(\"Progression of model performance with each epoch\", fontsize=20)\n",
    "plt.xlabel(\"Number of epochs\", fontsize=16)\n",
    "plt.xticks(range(0, 11), fontsize=14)\n",
    "plt.ylabel(\"Accuracy\", fontsize=16)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1), fontsize=14)\n",
    "plt.legend([\"Training accuracy\", \"Validation accuracy\"], fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"Weights/weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import cv2\n",
    "\n",
    "#im = cv2.imread(\"Data/Yes/Yes_2.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "#im = np.expand_dims(im, axis=0)\n",
    "#im = np.expand_dims(im, axis=-1)\n",
    "#prediction = model(im, training=False)\n",
    "#test_images.class_names[np.argmax(prediction, axis = 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Building data pipeline</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threading options to autotuning\n",
    "tf.config.threading.set_inter_op_parallelism_threads(0)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as file:\n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Specify validation split size in config\n",
    "# TODO: Specify batch size in config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that image_dataset_from_directory shuffles dataset by default during loading (can be turned off)\n",
    "    # Source: https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 490 files belonging to 49 classes.\n",
      "Using 368 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(config[\"Paths\"][\"Data\"],\n",
    "                                                       validation_split=0.25,\n",
    "                                                       subset=\"training\",\n",
    "                                                       seed=123,\n",
    "                                                       label_mode=\"categorical\",\n",
    "                                                       image_size=(config[\"General parameters\"][\"Image size\"],\n",
    "                                                                   config[\"General parameters\"][\"Image size\"]),\n",
    "                                                       batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(config[\"Paths\"][\"Data\"],\n",
    "                                                      validation_split=0.25,\n",
    "                                                      subset=\"train\",\n",
    "                                                      seed=123,\n",
    "                                                      label_mode=\"categorical\",\n",
    "                                                      image_size=(config[\"General parameters\"][\"Image size\"],\n",
    "                                                                  config[\"General parameters\"][\"Image size\"]),\n",
    "                                                      batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 490 files belonging to 49 classes.\n",
      "Using 368 files for training.\n",
      "Using 122 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = tf.keras.utils.image_dataset_from_directory(config[\"Paths\"][\"Data\"],\n",
    "                                                      validation_split=0.25,\n",
    "                                                      subset=\"both\",\n",
    "                                                      seed=123,\n",
    "                                                      label_mode=\"categorical\",\n",
    "                                                      image_size=(config[\"General parameters\"][\"Image size\"],\n",
    "                                                                  config[\"General parameters\"][\"Image size\"]),\n",
    "                                                      batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(\"Old_data/data_64x64/*/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load images and extract labels\n",
    "def process_paths(dir_name):\n",
    "    label = tf.strings.split(dir_name, os.sep)[-2]\n",
    "    return tf.io.read_file(dir_name), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ds = list_ds.map(process_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_raw, label_text in labeled_ds.take(1):\n",
    "    print(repr(image_raw.numpy()[:10]))\n",
    "    print()\n",
    "    print(label_text.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While large buffer_sizes shuffle more thoroughly,\n",
    "# they can take a lot of memory, and significant time to fill.\n",
    "# (quote: tensorflow.org/guide/data)\n",
    "labeled_ds = labeled_ds.shuffle(buffer_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch dataset and get full element shape propagation using drop_remainder=True\n",
    "batched_dataset = labeled_ds.batch(100, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in batched_dataset.take(1):\n",
    "    print([sample.numpy()[:1] for sample in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You do not have pycocotools installed, so KerasCV pycoco metrics are not available. Please run `pip install pycocotools`.\n",
      "You do not have pyococotools installed, so the `PyCOCOCallback` API is not available.\n",
      "You do not have Waymo Open Dataset installed, so KerasCV Waymo metrics are not available.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "from keras_cv.layers import Grayscale\n",
    "from model.preprocessing import AdaptiveThresholding, Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = Sequential(\n",
    "            [\n",
    "                Grayscale(),\n",
    "                Blurring(blurring_type=\"median\", kernel_size=3, sigma=None),\n",
    "                AdaptiveThresholding(thresholding_type=\"mean\", block_size=3, constant=0),\n",
    "                layers.Rescaling(scale=(1. / 255))\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(196, 196), dtype=float32, numpy=\n",
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline1(tf.ones([196, 196, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " grayscale_1 (Grayscale)     (None, 196, 196, 1)       0         \n",
      "                                                                 \n",
      " blurring_1 (Blurring)       None                      0         \n",
      "                                                                 \n",
      " adaptive_thresholding_1 (Ad  None                     0         \n",
      " aptiveThresholding)                                             \n",
      "                                                                 \n",
      " rescaling_1 (Rescaling)     None                      0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pipeline1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<model.preprocessing.Blurring at 0x238027e2d10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline1.layers[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
